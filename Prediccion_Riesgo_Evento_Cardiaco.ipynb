{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nqed1-G7o6lE"
   },
   "source": [
    "# Predicción de Riesgo de Evento Cardíaco con Señales de ECG Usando la Base de Datos PTB Diagnostic ECG y PTB-XL."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El proyecto se centra en la predicción del riesgo de eventos cardíacos utilizando registros de ECG (electrocardiogramas) de la base de datos PTB Diagnostic ECG y PTB-XL de PhysioNet. La finalidad es desarrollar un modelo de aprendizaje profundo que ayude a identificar pacientes en riesgo de sufrir eventos cardíacos, basándose en características extraídas de los datos electrocardiográficos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objetivo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Predecir el riesgo de eventos cardíacos, un enfoque clave para la atención preventiva y el tratamiento de enfermedades cardiovasculares.\n",
    "- Resaltar la importancia de este análisis para mejorar el diagnóstico temprano y el tratamiento.\n",
    "- Comparar el rendimiento de diferentes modelos de aprendizaje profundo en la predicción de eventos cardíacos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contexto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El infarto agudo de miocardio con elevación del segmento ST, conocido como STEMI (por sus siglas en inglés, ST-Elevation Myocardial Infarction), es una forma grave de ataque cardíaco caracterizada por una obstrucción completa de una de las arterias principales del corazón. Esta obstrucción provoca la interrupción del flujo sanguíneo, resultando en daño significativo al músculo cardíaco. El diagnóstico de STEMI se realiza mediante el análisis de los cambios en el electrocardiograma (ECG), donde la elevación del segmento ST indica una isquemia grave y un riesgo elevado de muerte si no se trata de manera inmediata."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metodología"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Obtención de datos** : Se descargan los datos de la base de datos PTB Diagnostic ECG y PTB-XL de PhysioNet.\n",
    "\n",
    "- Para la base de datos PTB Diagnostic ECG, se descarga la base de datos en su totalidad debido a que los registros a utilizar estan dispersos y la gran mayoria será utilizada para el análisis posterior.\n",
    "- Para la base de datos PTB-XL sólo se descarga una parte debido a que no se utiliza en su totalidad.\n",
    "  \n",
    "**Exploración de datos** :Se analizan las características de los datos y se visualizan los registros de ECG.\n",
    "- Se identifica la distribución de las clases STEMI y HC (Healthy Control) en la base de datos PTB Diagnostic ECG mediante el uso de un atributo \"comment\" propio de cada registro.\n",
    "- Se explicita la problematica de la base de datos PTB Diagnostic ECG, la cual se refiere al desbalance de clases respecto a los registros STEMI y HC.\n",
    "- Se explicita la solución seleccionada respecto a la problematica cual se refiere al uso de otra base de datos (PTB-XL) para obtener y balancear los registros HC (Clase minoritaria). \n",
    "  \n",
    "**Preprocesamiento de datos** : Se realizan tareas de limpieza y transformación de los datos para su uso en el modelo.\n",
    "- Los registros identificados como STEMI son copiados una carpeta para su posterior procesamiento.\n",
    "- Se eliminan los canales vx, vy y vz de los registros STEMI.\n",
    "- Se realiza un downsampling de los registros STEMI de 1000hz a 500Hz.\n",
    "- Se realiza un limpieza utilizando el algoritmo Butterworth para eliminar el ruido de los registros STEMI.\n",
    "- Los registros HC no son alterados en este proceso.\n",
    "   \n",
    "**Extracción de características**: Se extraen características relevantes de los registros de ECG.\n",
    "- Para el modelado simple, se extraen características de media, desviación estándar, valores minimo y valores máximos para los 12 canales de los registros STEMI y HC.\n",
    "- Para el modelado complejo, se extraen las caracteristicas de cada segmento QRS y ST de cada latido en cada canal. \n",
    " \n",
    "**Modelado**: Se entrena un modelo de aprendizaje profundo para predecir el riesgo de eventos cardíacos.\n",
    "- Uso de Random Forest para la clasificación de los registros STEMI y HC para cada modelado.\n",
    "  \n",
    "**Evaluación**: \n",
    "- Uso de la matriz de confusión para evaluar el rendimiento del modelo.\n",
    "- Uso de indicador f1 score para evaluar el rendimiento del modelo.\n",
    " \n",
    "**Guardado de modelo**\n",
    "- Se guarda el modelo entrenado para su uso futuro."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consideraciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EQivsHB1t1vX"
   },
   "source": [
    "*El procesamiento de los datos es lento debido a la cantidad de datos a utilizar (1,7gb con 549 registros de 290 sujetos de la base de datos PTB Diagonstic ECG Y 128mb de PTB-XL), por lo que se sugiere realizar este procesamiento de forma local. Mas información en https://research.google.com/colaboratory/local-runtimes.html*\n",
    "\n",
    "Con motivo de no saturar la memoria RAM durante el desarrollo de este proyecto, se decidió utilizar un enfoque de carga y uso inmediato de los datos, es decir, se carga un registro, se procesa y se elimina de la memoria para liberar espacio. Este enfoque puede ser lento, pero es efectivo para evitar problemas de memoria debido a la gran cantidad de datos a procesar. Este enfoque se utilizó debido a problematicas encontradas durante el desarrollo de este proyecto relacionados a uso intensivo de memoria RAM llegando a ocupar mas de 20gb y produciendo efectos tales como congelamientos o reinicios inesperados.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jz8Pg2E2tXNJ"
   },
   "source": [
    "Los datos fueron extraidos directamente de la página [Physionet.org](https://physionet.org/)\n",
    "\n",
    "Enlace PTB Diagnostic ECG: https://physionet.org/content/ptbdb/1.0.0/\n",
    "\n",
    "Enlace PTB-XL: https://physionet.org/content/ptb-xl/1.0.1/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instalación de librerías"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "| Biblioteca   | Descripción                                                                                                                                                                                                 |\n",
    "|--------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| **wfdb**     | La biblioteca wfdb (WaveForm DataBase) se utiliza para trabajar con datos de señales fisiológicas, como electrocardiogramas (ECG). Es útil para leer, escribir y procesar datos de señales fisiológicas almacenados en el formato de la base de datos WFDB. |\n",
    "| **Seaborn**  | seaborn es una biblioteca de visualización de datos basada en matplotlib. Se utiliza para crear gráficos estadísticos atractivos y fáciles de interpretar. Facilita la visualización de datos complejos con menos código. |\n",
    "| **Torch**    | Torch es la biblioteca principal de PyTorch, un marco de trabajo de aprendizaje profundo (deep learning). Se utiliza para construir y entrenar modelos de aprendizaje profundo. Es popular en la investigación y desarrollo de redes neuronales y otros algoritmos de machine learning. |\n",
    "| **Numpy**    | Biblioteca fundamental para la computación científica en Python. Se utiliza para trabajar con arreglos multidimensionales y matrices, y proporciona una gran colección de funciones matemáticas para operar con estos datos de manera eficiente. |\n",
    "| **Matplotlib** | Biblioteca de visualización de datos en Python. Se utiliza para crear gráficos estáticos, animados e interactivos en Python. Es muy versátil y permite generar una amplia variedad de gráficos, como líneas, barras, histogramas, dispersión, etc. |\n",
    "| **Boto3**    | Biblioteca de Amazon Web Services (AWS) para Python. Se utiliza para interactuar con los servicios de AWS, como S3, EC2, DynamoDB, entre otros. Facilita la automatización y gestión de recursos en la nube de AWS desde aplicaciones Python. |\n",
    "| **Pandas**   | Biblioteca de Python para la manipulación y análisis de datos. Se utiliza para trabajar con estructuras de datos como DataFrames, que permiten manipular, limpiar y analizar datos de manera eficiente. Es muy útil para tareas de preprocesamiento de datos. |\n",
    "| **Scikit-learn** | Es una biblioteca de aprendizaje automático en Python. Se utiliza para construir y evaluar modelos de machine learning. Proporciona herramientas para clasificación, regresión, clustering, reducción de dimensionalidad, y más. |\n",
    "| **Scipy**    | Biblioteca de Python que se basa en numpy y proporciona algoritmos y herramientas adicionales para la computación. Se utiliza para tareas de optimización, integración, interpolación, álgebra lineal, y otras operaciones matemáticas avanzadas. |\n",
    "| **biosppy** | Biblioteca de Python que permite identificar picos R de una señal dada. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalación de librerías\n",
    "\n",
    "%pip install wfdb\n",
    "%pip install seaborn\n",
    "%pip install torch\n",
    "%pip install numpy\n",
    "%pip install matplotlib\n",
    "%pip install pandas\n",
    "%pip install scikit-learn\n",
    "%pip install scipy\n",
    "%pip install boto3\n",
    "%pip install biosppy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fSB9CM2wpDwY"
   },
   "source": [
    "## Obtención de Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descarga de datos de la base de datos PTB Diagnostic ECG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La descarga de los datos en este documento se realiza de manera automatica utilizando la libreria boto3 de AWS, pero también se puede descargar manualmente desde el enlace original (https://physionet.org/content/ptbdb/1.0.0/). (Seguir las instrucciones de descarga manual en el bloque subsiguiente)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from botocore import UNSIGNED\n",
    "from botocore.config import Config\n",
    "import os\n",
    "\n",
    "# Configuración de variables\n",
    "bucket_name = \"physionet-open\"\n",
    "prefix = \"ptbdb/1.0.0/\"  # Carpeta en el bucket S3\n",
    "destination = \"./Databases/PTB-DIAGNOSTIC-DATABASE\" \n",
    "\n",
    "\n",
    "s3 = boto3.client('s3', config=Config(signature_version=UNSIGNED))\n",
    "\n",
    "# Inicializa la paginación\n",
    "continuation_token = None\n",
    "\n",
    "while True:\n",
    "    # Prepara los parámetros para la llamada a la API\n",
    "    params = {\n",
    "        'Bucket': bucket_name,\n",
    "        'Prefix': prefix\n",
    "    }\n",
    "    if continuation_token:\n",
    "        params['ContinuationToken'] = continuation_token\n",
    "\n",
    "    # Llama a list_objects_v2\n",
    "    objects = s3.list_objects_v2(**params)\n",
    "\n",
    "    # Verifica si hay objetos en la respuesta\n",
    "    if 'Contents' in objects:\n",
    "        for obj in objects['Contents']:\n",
    "            # Obtener el nombre del archivo y el subdirectorio en S3\n",
    "            s3_key = obj['Key']\n",
    "            \n",
    "            # Crear la ruta local completa para el archivo\n",
    "            local_file_path = os.path.join(destination, s3_key[len(prefix):])  # Omite el prefijo en la ruta local\n",
    "\n",
    "            # Crear directorios locales si no existen\n",
    "            os.makedirs(os.path.dirname(local_file_path), exist_ok=True)\n",
    "\n",
    "            # Verificar si el archivo ya existe antes de descargar\n",
    "            if not os.path.exists(local_file_path):\n",
    "                # Descargar el archivo\n",
    "                try:\n",
    "                    s3.download_file(bucket_name, s3_key, local_file_path)\n",
    "                    print(f\"Descargado: {s3_key} a {local_file_path}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error al descargar {s3_key}: {e}\")\n",
    "            else:\n",
    "                print(f\"El archivo ya existe: {local_file_path}\")\n",
    "\n",
    "    # Verifica si hay un token de continuación\n",
    "    continuation_token = objects.get('NextContinuationToken')\n",
    "    if not continuation_token:\n",
    "        break  # Salir del bucle si no hay más objetos\n",
    "\n",
    "print(\"Descarga completada.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Descarga manual de base de datos PTB Diagnostic Database (opcional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La descarga manual y directa desde physionet en general es mas lenta por lo que se recomienda utilizar el metodo anterior de AWS. En caso de necesitar hacer la descarga manual, se debe asegurar tener instalado el [AWS CLI](https://docs.aws.amazon.com/es_es/cli/latest/userguide/getting-started-install.html) (_Click para más información_) para efectuar la descarga utilizando el comando ```aws s3 sync --no-sign-request s3://physionet-open/ptbdb/1.0.0/ DESTINATION```. \n",
    "\n",
    "**Nota:** Reemplazar DESTINATION por la ruta donde se desea guardar los datos.\n",
    "\n",
    "La carpeta de la base de datos descargada debe tener de nombre \"PTB-DIAGNOSTIC-DATABASE\" y contener las carpetas de los pacientes con los archivos .dat, .hea y .xyz. \n",
    "Esta carpeta debe estar contenida en \"Databases\" la cual debe estar en la raiz del proyecto tal como se muestra en la siguiente estructura:\n",
    "\n",
    "```\n",
    "├── Databases\n",
    "│   ├── PTB-DIAGNOSTIC-DATABASE\n",
    "│   │   ├── patient001\n",
    "│   │   │   ├── s0010_re.dat\n",
    "│   │   │   ├── s0010_re.hea\n",
    "│   │   │   ├── s0010_re.xyz\n",
    "│   │   │   ├── ...\n",
    "│   │   ├── patient002\n",
    "│   │   │   ├── s0015lre.dat\n",
    "│   │   │   ├── s0015lre.hea\n",
    "│   │   │   ├── s0015lre.xyz\n",
    "│   │   │   ├── ...\n",
    "│   │   ├── ...\n",
    "│   ├── PTB-XL\n",
    "├── Readme.md\n",
    "├── Prediccion_Riesgo_Evento_Cardiaco.ipynb\n",
    "└── .gitignore\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descarga de datos de la base de datos PTB-XL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De la misma manera en que se descargó la base de datos PTB Diagnostic Database, se descarga la base de datos PTB-XL pero sólo una sección de esta.\n",
    "\n",
    "La descarga selectiva de esta base de datos se compone de las siguientes características:\n",
    "\n",
    "- Se descargan los documentos alojados en la carpeta raiz de la base de datos\n",
    "- Solo se descarga la subcarpeta \"00000\" de la carpeta \"records500\"\n",
    "- Las demás carpetas no se descargan\n",
    "\n",
    "Las restricciones impuestas a la descarga es para salvar tiempo y espacio en disco, ya que esta base de datos en su carpeta \"00000\" contiene suficiente información para realizar el análisis posterior.\n",
    "\n",
    "Seguir las instrucciones de descarga manual en el bloque subsiguiente si se requiere la descarga de los datos sin utilizar el codigo a continuación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from botocore import UNSIGNED\n",
    "from botocore.config import Config\n",
    "import os\n",
    "\n",
    "# Configuración de variables\n",
    "bucket_name = \"physionet-open\"\n",
    "prefix = \"ptb-xl/1.0.3/\"  # Carpeta en el bucket S3\n",
    "destination = \"./Databases/PTB-XL\"  # Cambia esto a la ruta local de destino\n",
    "\n",
    "s3 = boto3.client('s3', config=Config(signature_version=UNSIGNED))\n",
    "\n",
    "# Inicializa la paginación\n",
    "continuation_token = None\n",
    "\n",
    "while True:\n",
    "    # Prepara los parámetros para la llamada a la API\n",
    "    params = {\n",
    "        'Bucket': bucket_name,\n",
    "        'Prefix': prefix\n",
    "    }\n",
    "    if continuation_token:\n",
    "        params['ContinuationToken'] = continuation_token\n",
    "\n",
    "    # Llama a list_objects_v2\n",
    "    objects = s3.list_objects_v2(**params)\n",
    "\n",
    "    # Verifica si hay objetos en la respuesta\n",
    "    if 'Contents' in objects:\n",
    "        for obj in objects['Contents']:\n",
    "            # Obtener el nombre del archivo y el subdirectorio en S3\n",
    "            s3_key = obj['Key']\n",
    "            \n",
    "            # Verificar si el archivo pertenece a las carpetas que queremos evitar\n",
    "            if 'records100' in s3_key or('records500' in s3_key and '00000' not in s3_key):\n",
    "                print(\"El archivo \"+s3_key+\" ha sido ignorado para su descarga\")\n",
    "                continue\n",
    "            \n",
    "            # Crear la ruta local completa para el archivo\n",
    "            local_file_path = os.path.join(destination, s3_key[len(prefix):])  # Omite el prefijo en la ruta local\n",
    "\n",
    "            # Crear directorios locales si no existen\n",
    "            os.makedirs(os.path.dirname(local_file_path), exist_ok=True)\n",
    "\n",
    "            # Verificar si el archivo ya existe antes de descargar\n",
    "            if not os.path.exists(local_file_path):\n",
    "                # Descargar el archivo\n",
    "                try:\n",
    "                    s3.download_file(bucket_name, s3_key, local_file_path)\n",
    "                    print(f\"Descargado: {s3_key} a {local_file_path}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error al descargar {s3_key}: {e}\")\n",
    "            else:\n",
    "                print(f\"El archivo ya existe: {local_file_path}\")\n",
    "\n",
    "    # Verifica si hay un token de continuación\n",
    "    continuation_token = objects.get('NextContinuationToken')\n",
    "    if not continuation_token:\n",
    "        break  # Salir del bucle si no hay más objetos\n",
    "\n",
    "print(\"Descarga completada.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Descarga manual de base de datos PTB-XL (opcional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La descarga manual y directa desde physionet en general es mas lenta por lo que se recomienda utilizar el metodo anterior de AWS. En caso de necesitar hacer la descarga manual, se debe asegurar tener instalado el [AWS CLI](https://docs.aws.amazon.com/es_es/cli/latest/userguide/getting-started-install.html) (_Click para más información_) para efectuar la descarga utilizando los siguientes comandos: \n",
    "- ```aws s3 sync --no-sign-request s3://physionet-open/ptb-xl/1.0.3/records500/00000/ DESTINATION```. \n",
    "- ```aws s3 sync --no-sign-request s3://physionet-open/ptb-xl/1.0.3/ptbxl_database.csv DESTINATION```\n",
    "\n",
    "**Nota:** Reemplazar DESTINATION por la ruta donde se desea guardar los datos.\n",
    "\n",
    "La carpeta de la base de datos descargada debe tener de nombre \"PTB-XL\" y contener la carpeta \"records500\" y la subcarpeta \"00000\" con los archivos .dat y .hea. \n",
    "Esta carpeta debe estar contenida en \"Databases\" la cual debe estar en la raiz del proyecto tal como se muestra en la siguiente estructura:\n",
    "\n",
    "```\n",
    "├── Databases\n",
    "│   ├── PTB-XL\n",
    "│   │   ├── records500\n",
    "│   │   │   ├── 00000\n",
    "│   │   │   │   ├── 00001_hr.dat\n",
    "│   │   │   │   ├── 00001_hr.hea\n",
    "│   │   │   │   ├── 00002_hr.dat\n",
    "│   │   │   │   ├── 00002_hr.hea\n",
    "│   │   │   │   ├── 00003_hr.dat\n",
    "│   │   │   │   ├── 00003_hr.hea\n",
    "│   │   │   │   ├── ...\n",
    "│   │   ├── ptbxl_database.csv\n",
    "│   ├── PTB-DIAGNOSTIC-DATABASE\n",
    "├── Readme.md\n",
    "├── Prediccion_Riesgo_Evento_Cardiaco.ipynb\n",
    "└── .gitignore\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Establecimiento de variables de referencia a directorios y archivos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui se establecen las variables que se utilizarán para hacer referencia a los archivos y datos correspondientes a los registros ECG de ambas bases de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PTB Diagnostic ECG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ntt169yxjbSC"
   },
   "outputs": [],
   "source": [
    "folder_path_ptb_diagnostic = './Databases/PTB-DIAGNOSTIC-DATABASE' # Ruta a base de datos PTB-DIAGNOSTIC-DATABASE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4TeUb-BkkZ9F"
   },
   "source": [
    "\n",
    "\n",
    "Aqui se utiliza el archivo RECORDS que contiene todas las referencias de los nombres de los pacientes como tambien de sus archivos asociados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CugO0bsmjr4x",
    "outputId": "1d8b324b-e187-4b35-c828-275447767a6f"
   },
   "outputs": [],
   "source": [
    "ruta_records = folder_path_ptb_diagnostic + '/RECORDS'\n",
    "\n",
    "# Leer el archivo 'records' para obtener la lista de archivos\n",
    "with open(ruta_records, 'r') as f:\n",
    "    registros = f.read().splitlines()\n",
    "\n",
    "# Ver las rutas de los registros\n",
    "print(registros)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PTB-XL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ruta del archivo ptbxl_database.csv el cual contiene la información de cada registro de la base de datos.\n",
    "ruta_csv_ptb_xl = './Databases/PTB-XL/ptbxl_database.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ruta_records_ptb_xl = './Databases/PTB-XL/records500/00000/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identificación de Pacientes STEMI y Sanos (HC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La base de datos PTB Diagnostic ECG contiene un atributo llamado \"comments\" el cual contiene información relevante sobre el paciente, en este caso se busca identificar a los pacientes que han sufrido un infarto agudo de miocardio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Establecimiento de funciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En los siguientes bloques se definen funciones relacionadas con la busqueda de pacientes STEMI Y HC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wfdb\n",
    "import os\n",
    "\n",
    "locations_frecuencia = {}\n",
    "\n",
    "# Busca los nombres y frecuencias de cada localización  de un registro dado\n",
    "def buscarLocations(registro):\n",
    "    # Obtener la localización del registro\n",
    "    location = registro.comments[5].split(':')[1].strip()\n",
    "    # Verificar si la localización ya está en el diccionario\n",
    "    if location in locations_frecuencia:\n",
    "        # Incrementar la frecuencia\n",
    "        locations_frecuencia[location]['frec'] += 1\n",
    "    else:\n",
    "        # Añadir la localización al diccionario con su frecuencia inicial\n",
    "        locations_frecuencia[location] = {'nombre': location, 'frec': 1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta función permite filtrar los pacientes STEMI y HC. Además de contar la cantidad de localizaciones en los registros STEMI y la cantidad de registros HC de la base de datos PTB Diagnostic ECG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemi_avoid_locations = ['no', 'n/a', 'unknown']\n",
    "locations_frecuencia_filtrados = {}\n",
    "healthy_locations = {}\n",
    "\n",
    "# Busca los nombres y frecuencias de cada localización de un registro dado\n",
    "# Tambien hace una identificación de los registros STEMI y HC mediante la razon de ingreso 'Myocardial infarction'\n",
    "def buscarLocationsFiltered(registro):\n",
    "    # Obtener la razon de ingreso\n",
    "    reason = registro.comments[4].split(':')[1].strip()\n",
    "    # Obtener la localización del registro\n",
    "    location = registro.comments[5].split(':')[1].strip()\n",
    "    # Verificar si la razón es 'Myocardial infarction'\n",
    "    if reason == 'Myocardial infarction':\n",
    "        # Verificar si la localización no está en la lista de localizaciones a evitar\n",
    "        if location not in stemi_avoid_locations:\n",
    "            # Añadir la localización al diccionario de localizaciones con STEMI\n",
    "            if location in locations_frecuencia_filtrados:\n",
    "                locations_frecuencia_filtrados[location]['frec'] += 1\n",
    "            else:\n",
    "                locations_frecuencia_filtrados[location] = {'nombre': location, 'frec': 1}\n",
    "    elif reason == 'Healthy control': # Verificar si la razón es 'Healthy control'\n",
    "        # Añadir la localización al diccionario de localizaciones sanas\n",
    "        if reason in healthy_locations:\n",
    "                healthy_locations[reason]['frec'] += 1\n",
    "        else:\n",
    "            healthy_locations[reason] = {'nombre': reason, 'frec': 1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta función permite iterar sobre la base de datos PTB Diagnostic Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import wfdb\n",
    "# Esta función itera sobre los registros de la base de datos PTB Diagnostic\n",
    "# Admite un path que es la ruta de la base de datos, una lista de registros y una función que se ejecutará en cada registro\n",
    "def PTBDiagnosticDatabaseIterator(path,registros,funcion):\n",
    "    for registro in registros:\n",
    "        try:\n",
    "            # Construir la ruta completa para el archivo\n",
    "            record_path = os.path.join(path, registro)\n",
    "\n",
    "            # Cargar el archivo\n",
    "            record = wfdb.rdrecord(record_path)\n",
    "\n",
    "            # Ejecutar la función con el registro cargado\n",
    "            funcion(record)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error cargando {record_path}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta función permite mostrar la información de un registro dado de la base de datos PTB Diagnostic ECG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar atributos de un registro\n",
    "def showAtributesPTB_Diagnostic(registro):\n",
    "    print(f\"record_name: {registro.record_name}\")\n",
    "    print(f\"n_sig: {registro.n_sig}\")\n",
    "    print(f\"fs: {registro.fs} Hz\")\n",
    "    print(f\"sig_name: {registro.sig_name}\")\n",
    "    print(f\"sig_len:  {registro.sig_len}\")\n",
    "    print(f\"comments: {registro.comments}\")\n",
    "    print(f\"p_signal: {registro.p_signal}\")\n",
    "    print()\n",
    "\n",
    "    print(\"Keys importantes: \")\n",
    "    print(f\"Reason for admission: {registro.comments[4].split(':')[1].strip()}\")\n",
    "    print(f\"Acute infarction (localization): {registro.comments[5].split(':')[1].strip()}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identificación de atributos de la base de datos PTB Diagnostic ECG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se muestra los atributos de un registro de la base de datos PTB Diagnostic ECG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construcción de la ruta al archivo\n",
    "record_path = os.path.join(folder_path_ptb_diagnostic, registros[0])\n",
    "\n",
    "# Cargar el archivo\n",
    "record = wfdb.rdrecord(record_path)\n",
    "\n",
    "# Mostrar atributos del registro\n",
    "showAtributesPTB_Diagnostic(record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Análisis de los atributos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada registro de la base de datos PTB Diagnostic ECG contiene al menos los siguientes atributos:\n",
    "\n",
    "- **record_name**: Nombre del registro.\n",
    "- **n_sig**: Número de señales en el registro.\n",
    "- **fs**: Frecuencia de muestreo de las señales.\n",
    "- **sig_name**: Nombre de las señales.\n",
    "- **sig_len**: Longitud de las señales.\n",
    "- **comments**: Comentarios sobre el registro.\n",
    "- **p_signal**: Señales físicas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede observar, en el atributo 'comments' existe una lista de información relevante sobre el paciente, en la cual se puede identificar que el valor de la llave **'Reason for admission'** clasifica a al registro como _'Myocardal infarction'_ en este caso. También existe la clave **'Acute infarction (localization)'** que indica la localización del infarto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basado en lo anterior, se puede identificar los registros STEMI que tengan como razon de admision \"Myocardal infarction\" pero se debe verificar que la localización del infarto sea correcta. Razón por la cual se realiza una busqueda de valores unicos en la llave **'Acute infarction (localization)'** para hacer un filtrado y obtener registros con la mayor información de calidad posible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Búsqueda de valores únicos en la key 'Acute infarction (localization)'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui se llama a la función iteradora de la base de datos PTB Diagnostic ECG para buscar los valores únicos en la key 'Acute infarction (localization)' en cada registro "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Llamado a función para buscar las localizaciones de los infartos\n",
    "PTBDiagnosticDatabaseIterator(folder_path_ptb_diagnostic,registros,buscarLocations)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui se listan los valores unicos encontrados:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('Frecuencia de cada valor único del atributo Acute infarction (localization):')\n",
    "for location, data in locations_frecuencia.items():\n",
    "    print(f\"{data['nombre']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui se muestra un histograma de frecuencias de cada localización encontrada en el apartado 'Acute infarction (localization)' en el atributo 'comments' de la base de datos PTB Diagnostic ECG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot de frecuencias de localizaciones unicas\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(16, 6))\n",
    "frequencies = [data['frec'] for data in locations_frecuencia.values()]\n",
    "bars = plt.barh(list(locations_frecuencia.keys()), frequencies)\n",
    "plt.title('Frecuencias de localizaciones unicas')\n",
    "plt.ylabel('Acute infarction (localization)')\n",
    "plt.xlabel('Frecuencia')\n",
    "\n",
    "# Agregar números encima de cada barra\n",
    "for bar in bars:\n",
    "    width = bar.get_width()\n",
    "    plt.text(width, bar.get_y() + bar.get_height()/2, int(width), ha='left', va='center')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cabe destacar que estas localizaciones son directamente obtenidas de los registros EGC y no presentan un filtrado o corrección de etiquetas hasta el momento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtrado de registros que tengan localización descrita en su atributo 'comments'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui se hace un filtrado de los registros que contengan información relacionada a STEMI en su atributo 'comments'. Para esto, se quitan los registros que contengan **'no'**,**'n/a'** y **'unknown'** en el apartado de 'Acute infarction (localization)'.\n",
    "La elección de los valores a filtrar se debe a que no aportan información relevante para el análisis posterior:\n",
    "- **'no'**: Valor ambiguo que puede significar que no hubo Infarto o no hay valor.\n",
    "- **'n/a'**: Valor ambiguo que puede significar que no hubo Infarto o no hay valor.\n",
    "- **'unknown'**: Indica que no se conoce la localización del infarto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De forma adicional al filtrado anterior, tambien se hace una segregación de los registros que contengan el valor **'Healthy control'** como razon de llegada para obtener los registros HC de la base de datos PTB Diagnostic ECG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejecución de filtrado y segregación de registros STEMI Y HC de la base de datos PTB Diagnostic\n",
    "PTBDiagnosticDatabaseIterator(folder_path_ptb_diagnostic,registros,buscarLocationsFiltered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui se gráfica el histograma de frecuencias de localizaciones STEMI luego de ser filtrados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Plot de frecuencias de localizaciones unicas\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Definir una paleta de colores\n",
    "palette = sns.color_palette(\"husl\", len(locations_frecuencia_filtrados))\n",
    "\n",
    "plt.figure(figsize=(16, 6))\n",
    "stemi_frequencies = [data['frec'] for data in locations_frecuencia_filtrados.values()]\n",
    "\n",
    "plt.title('Frecuencias de localizaciones unicas (Filtrados)')\n",
    "bars = plt.barh(list(locations_frecuencia_filtrados.keys()), stemi_frequencies, color=palette)\n",
    "plt.ylabel('Acute infarction (localization)')\n",
    "plt.xlabel('Frecuencia')\n",
    "\n",
    "# Agregado de cantidades encima de cada barra\n",
    "for bar in bars:\n",
    "    width = bar.get_width()\n",
    "    plt.text(width, bar.get_y() + bar.get_height()/2, int(width), ha='left', va='center')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gráfico comparativo de registros STEMI y Sanos (HC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este apartado se muestra la cantidad de registros obtenidos de la base de datos PTB Diagnostic ECG clasificandolos en Infarto Agudo de Miocardio con Elevación del Segmento ST (STEMI) y sanos (HC)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histograma para mostrar la cantidad total de registros de pacientes sanos y stemi\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "stemi_total = sum([data['frec'] for data in locations_frecuencia_filtrados.values()])\n",
    "healthy_total = sum([data['frec'] for data in healthy_locations.values()])\n",
    "\n",
    "bar_stemi = plt.bar('STEMI', stemi_total, color='red')\n",
    "bar_healthy = plt.bar('HC', healthy_total, color='green')\n",
    "\n",
    "# Agregar números encima de cada barra\n",
    "for bar in [bar_stemi, bar_healthy]:\n",
    "    height = bar[0].get_height()\n",
    "    plt.text(bar[0].get_x() + bar[0].get_width() / 2.0, height, '%d' % int(height), ha='center', va='bottom')\n",
    "\n",
    "plt.title('Cantidad total de registros de pacientes STEMI y Sanos (HC)')\n",
    "plt.xlabel('Tipo de paciente')\n",
    "plt.ylabel('Cantidad total de registros')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problemática identificada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existe una claro desbalanceo de pacientes identificados con Infarto Agudo de Miocardio con Elevación del Segmento ST (STEMI) y pacientes sanos (HC) en la base de datos PTB Diagnostic ECG. Este desbalanceo puede afectar el rendimiento de los modelos de aprendizaje automático, ya que el modelo puede tener dificultades para aprender de los datos minoritarios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solución Propuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Surgieron las siguientes ideas para abordar el desbalanceo de clases en la base de datos PTB Diagnostic ECG:\n",
    "\n",
    "1. **Uso de técnicas de resampling**: Se puede utilizar técnicas de resampling como oversampling o undersampling para balancear las clases. Oversampling puede generar nuevos ejemplos de la clase minoritaria, mientras que undersampling puede eliminar ejemplos de la clase mayoritaria.\n",
    "2. **Generación de datos sintéticos**: Se pueden generar datos sintéticos para la clase minoritaria utilizando técnicas como SMOTE (Synthetic Minority Over-sampling Technique) o ADASYN (Adaptive Synthetic Sampling Approach).\n",
    "3. **Ajuste de pesos de clase**: Algunos algoritmos de machine learning permiten ajustar los pesos de clase para penalizar más los errores en la clase minoritaria. Esto puede ayudar al modelo a prestar más atención a los ejemplos de la clase minoritaria.\n",
    "4. **Busqueda de pacientes sanos en otra base de datos**: Se puede utilizar registros de pacientes sanos de otra base de datos para aumentar la cantidad de ejemplos de la clase minoritaria.\n",
    "\n",
    "Respecto a las soluciones propuestas, se da selección a la **búsqueda de registros de pacientes sanos en otra base de datos**, en este caso la base de datos PTB-XL."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargando nuevos datos de registros de pacientes sanos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se decidió obtener nuevos registros de otra base de datos debido al desbalanceo de la base de datos PTB Diagnostic ECG. Para esto se utilizó la base de datos PTB-XL, la cual contiene registros de pacientes control sanos (HC)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Establecimientos de funciones "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Muestra los atributos de un registro de la base de datos PTB-XL\n",
    "def showAtributesPTB_XL(registro):\n",
    "    print(f\"record_name: {registro.record_name}\")\n",
    "    print(f\"n_sig: {registro.n_sig}\")\n",
    "    print(f\"fs: {registro.fs} Hz\")\n",
    "    print(f\"sig_name: {registro.sig_name}\")\n",
    "    print(f\"sig_len:  {registro.sig_len}\")\n",
    "    print(f\"comments: {registro.comments}\")\n",
    "    print(f\"p_signal: {registro.p_signal}\")\n",
    "    print()\n",
    "\n",
    "# Se obtiene un registro de la base de datos PTB-XL utilizando un id\n",
    "def obtainRecordPTB_XL(ecg_id):\n",
    "    # Carga el archivo CSV de la base de datos PTB-XL\n",
    "    record_path = os.path.join(ruta_records_ptb_xl, ecg_id)\n",
    "    # Cargar el archivo\n",
    "    record = wfdb.rdrecord(record_path)\n",
    "    \n",
    "    return record"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identificación de atributos de la base de datos PTB-XL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se muestra los atributos de un registro de la base de datos PTB-XL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Leer el archivo csv\n",
    "csv_ptb_xl_data = pd.read_csv(ruta_csv_ptb_xl)\n",
    "\n",
    "# Obtener el primer ecg_id de csv_ptb_xl_data, se le agrega tantos 0 para tener 5 digitos antes de agregar\n",
    "# un sufijo '_hr' para obtener el nombre del archivo del registro\n",
    "ecg_id = f\"{str(csv_ptb_xl_data['ecg_id'][0]).zfill(5)}_hr\"\n",
    "\n",
    "# Se obtiene un registro cargado en wfdb\n",
    "ptb_xl_record_demo = obtainRecordPTB_XL(ecg_id)\n",
    "\n",
    "# Se imprime los atributos del registro\n",
    "showAtributesPTB_XL(ptb_xl_record_demo)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Análisis de los atributos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede observar, los atributos del registro de la base de datos PTB-XL comparten similitudes con los de la base de datos PTB Diagnostic ECG, pero con algunas diferencias a continuación:\n",
    "\n",
    "- **fs**: 500 Hz\n",
    "- **comments**: Vacío\n",
    "\n",
    "Los registros de la base de datos PTB-XL no tienen información en el atributo 'comments' por lo tanto su carga de datos para clasificarlos  se debe de realizar de una manera distinta a la realizada con la base de datos PTB Diagnostic ECG.\n",
    "\n",
    "En este caso, la información referida a los diagnosticos y etiquetas estan registradas en un .csv llamado ptbxl_database.csv.\n",
    "\n",
    "Respecto a la frecuencia de muestreo, esta es diferente e inferior a los 1000hz de la base de datos PTB Diagnostic ECG.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtención de datos de base de datos PTB-XL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Para esto, se debió realizar un proceso de filtrado de los registros de la base de datos PTB-XL, donde se seleccionaron los registros que no contenían información relacionada a enfermedades cardíacas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui se retornan los ids de los ecg de registros que contengan '{'NORM': 100.0, 'SR': 0.0}' en el atributo 'scp_codes'. Solo se cargan los primeros 346 registros para el balanceo de clases con los datos STEMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# extraer las filas en donde su atributo scp_codes contiene 'NORM'\n",
    "\n",
    "# Aqui se hace una busqueda en la columna scp_codes para encontrar los registros que contienen 'NORM' retornando solo\n",
    "# los primero 346 elementos encontrados. Luego se le aplica una funcion lambda que rellena el nombre del registro\n",
    "# con 0 para obtener 5 digitos en total para luego concatenar un guión bajo seguido de las letras 'hr'.\n",
    "hc_records = csv_ptb_xl_data[csv_ptb_xl_data['scp_codes'].str.contains(\"{'NORM': 100.0, 'SR': 0.0}\")]['ecg_id'].head(346).astype(str).apply(lambda x: x.zfill(5) + '_hr')\n",
    "\n",
    "# ver las filas seleccionadas\n",
    "print('Total de HC_records: ', len(hc_records))\n",
    "\n",
    "hc_records.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una de las principales diferencias con los registros STEMI es la frecuencia de muestreo de esa nueva base de datos, los cuales los registros estan a 500hz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparación de registros STEMI y HC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histograma de cantidad de registros STEMI de la viable stemi_records y HC_records\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.bar(['STEMI', 'HC'], [stemi_total, len(hc_records)], color=['red', 'green'])\n",
    "plt.title('Cantidad de registros STEMI y HC')\n",
    "plt.xlabel('Tipo de registro')\n",
    "plt.ylabel('Cantidad de registros')\n",
    "\n",
    "# Agregar números encima de cada barra\n",
    "for bar in bars:\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, yval + 5, int(yval), ha='center', va='bottom')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al obtener un set de registros balanceados se puede avanzar a la siguiente etapa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesamiento de Señales ECG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el procesamiento de las señales ECG se realizaran las siguientes tareas:\n",
    "- **Guardado de registros STEMI** en sus respectivo directorio para su procesamiento.\n",
    "- **Eliminación de canales de posicion de electrodos** identificando los nombres Vx, Vy y Vz.\n",
    "- **Downsampling de canales** de registros STEMI de 1000 a 500 Hz. \n",
    "- **Filtrado de ruido** mediante un filtro pasa banda Butterworth de 0.67 a 30 Hz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Permite iterar la base de datos de PTB-XL\n",
    "def PTBXL_Iterator(function):\n",
    "    for registro in hc_records:\n",
    "        try:\n",
    "            # Construir la ruta completa para el archivo\n",
    "            record_path = os.path.join('./Databases/PTB-XL/records500/00000/', registro)\n",
    "\n",
    "            # Cargar el archivo\n",
    "            record = wfdb.rdrecord(record_path)\n",
    "\n",
    "            function(record)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error cargando {record_path}: {e}\")\n",
    "\n",
    "# Permite guardar un registro de la base de datos PTB Diagnostric ECG en el disco \n",
    "# Verifica tambien que el registro esté catalogado como 'Myocardial infarction'\n",
    "def PTBDiagnostic_Writer(record):\n",
    "    folder = ''\n",
    "\n",
    "    if record.comments[4].split(':')[1].strip() == 'Myocardial infarction':\n",
    "        if record.comments[5].split(':')[1].strip() not in stemi_avoid_locations:\n",
    "            # print(record.comments[5].split(':')[1].strip())\n",
    "            folder = 'STEMI' \n",
    "\n",
    "    if folder != '':\n",
    "        outputPath = os.path.join('./Preprocess/'+folder+'/')\n",
    "        # Crear directorio local si no existe\n",
    "        os.makedirs(os.path.dirname(outputPath), exist_ok=True)\n",
    "\n",
    "        # Agregar la ruta a un archivo RECORDS en la misma carpeta\n",
    "        with open(os.path.join(outputPath, 'STEMI_RECORDS'), 'a') as f:\n",
    "            f.write(f'{record.record_name}\\n')\n",
    "\n",
    "        wfdb.wrsamp(\n",
    "        record_name=record.record_name,  # Nombre del registro\n",
    "        write_dir=outputPath,        # Nombre completo del archivo con ruta\n",
    "        fs=record.fs,               # Frecuencia de muestreo\n",
    "        units=record.units,         # Unidades de las señales\n",
    "        sig_name=record.sig_name,   # Nombres de las señales\n",
    "        p_signal=record.p_signal            # La señal en formato numpy array\n",
    "        )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui se hace uso de la función PTBDiagnostic_Writer el cual busca los registros STEMI y los guarda en la carpeta ./Preprocess/STEMI/ . Adicionalmente se agrega un archivo STEMI_RECORDS para tener un listado de todos los registros almacenados en esa carpeta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PTBDiagnosticDatabaseIterator(folder_path_ptb_diagnostic,registros,PTBDiagnostic_Writer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminación de canales de posición de electrodos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los registros STEMI contienen información de la posición de los electrodos por lo tanto se procede a eliminar estos canales de los registros debido a que no aportan información relevante para el análisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "folder_path_preprocess_stemi = './Preprocess/STEMI'\n",
    "ruta_records_stemi = os.path.join(folder_path_preprocess_stemi + '/STEMI_RECORDS')\n",
    "\n",
    "# Eliminar los canales vx, vy y vz\n",
    "def deleteStemiLeadPositions(record):\n",
    "        record.sig_name = record.sig_name[:12]\n",
    "        record.p_signal = record.p_signal[:, :12]\n",
    "        record.units = record.units[:12]\n",
    "\n",
    "\n",
    "        # Sobreescribir registro stemi\n",
    "        wfdb.wrsamp(\n",
    "        record_name=record.record_name,  # Nombre del registro\n",
    "        write_dir=folder_path_preprocess_stemi,        # Nombre completo del archivo con ruta\n",
    "        fs=record.fs,               # Frecuencia de muestreo\n",
    "        units=record.units,         # Unidades de las señales\n",
    "        sig_name=record.sig_name,   # Nombres de las señales\n",
    "        p_signal=record.p_signal            # La señal en formato numpy array\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "# Leer el archivo 'records' para obtener la lista de archivos\n",
    "with open(ruta_records_stemi, 'r') as f:\n",
    "    registros_stemi = f.read().splitlines()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminando los canales de los registros STEMI y guardandolos en el directorio Preprocess/STEMI/\n",
    "PTBDiagnosticDatabaseIterator(folder_path_preprocess_stemi,registros_stemi, deleteStemiLeadPositions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downsampling de registros STEMI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se realiza un downsampling de los registros STEMI de 1000 a 500 Hz para que coincida con la frecuencia de muestreo de los registros HC obtenido de la base de datos PTB-XL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from scipy.signal import resample\n",
    "import numpy as np\n",
    "# Downsample de señales de los registros stemi_records de 1000hz a 500 Hz\n",
    "\n",
    "def downsample_ecg_to_500hz(record):\n",
    "\n",
    "    downsampled_signals = []\n",
    "    for signal in record.p_signal.T:\n",
    "        new_length = signal.shape[0] // 2\n",
    "        downsampled_signal = resample(signal, new_length)\n",
    "        downsampled_signals.append(downsampled_signal)\n",
    "    \n",
    "    record.p_signal = np.array(downsampled_signals).T\n",
    "\n",
    "\n",
    "    # Sobreescribir registro stemi\n",
    "    wfdb.wrsamp(\n",
    "    record_name=record.record_name,  # Nombre del registro\n",
    "    write_dir=folder_path_preprocess_stemi,        # Nombre completo del archivo con ruta\n",
    "    fs=500,               # Frecuencia de muestreo\n",
    "    units=record.units,         # Unidades de las señales\n",
    "    sig_name=record.sig_name,   # Nombres de las señales\n",
    "    p_signal=record.p_signal            # La señal en formato numpy array\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui se hace uso de la función downsample_ecg_to_500hz para realizar el downsampling de los registros STEMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disminuyendo de 1000hz a 500hz\n",
    "PTBDiagnosticDatabaseIterator(folder_path_preprocess_stemi,registros_stemi, downsample_ecg_to_500hz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtrado de ruido en señales ECG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se realiza un filtrado de ruido en las señales ECG mediante un filtro pasa banda Butterworth de 0.67 a 30 Hz a los registros STEMI.\n",
    "A los registros HC no se les aplica este filtro debido a que ya se encuentran filtrados en la base de datos PTB-XL."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creación de función de filtro butterworth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.signal import butter, filtfilt\n",
    "\n",
    "def butter_bandpass(lowcut, highcut, fs, order=3):\n",
    "    nyquist = 0.5 * fs  # Frecuencia de Nyquist\n",
    "    low = lowcut / nyquist\n",
    "    high = highcut / nyquist\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    return b, a\n",
    "\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order=3):\n",
    "    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "    y = filtfilt(b, a, data)\n",
    "    return y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Función para hacer el filtrado en todas las señales de un registro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Parámetros del filtro\n",
    "lowcut = 0.67  # Frecuencia mínima (Hz)\n",
    "highcut = 30.0  # Frecuencia máxima (Hz)\n",
    "fs = 500  # Frecuencia de muestreo (Hz), 1 kHz para la base de datos PTB, 0,5 kHz para los datos preprocesados\n",
    "\n",
    "def filter_ecg_records(record):\n",
    "\n",
    "    for signal in record.p_signal.T:\n",
    "        filtered_signal = butter_bandpass_filter(signal, lowcut, highcut, fs, order=3)\n",
    "      \n",
    "        signal[:] = filtered_signal\n",
    "\n",
    "\n",
    "        \n",
    "    # Sobreescribir registro stemi\n",
    "    wfdb.wrsamp(\n",
    "    record_name=record.record_name,                 # Nombre del registro\n",
    "    write_dir=folder_path_preprocess_stemi,         # Nombre completo del archivo con ruta\n",
    "    fs=fs,                                          # Frecuencia de muestreo\n",
    "    units=record.units,                             # Unidades de las señales\n",
    "    sig_name=record.sig_name,                       # Nombres de las señales\n",
    "    p_signal=record.p_signal                        # La señal en formato numpy array\n",
    "    ) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uso del filtro butterworth en las señales ECG de registros STEMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PTBDiagnosticDatabaseIterator(folder_path_preprocess_stemi,registros_stemi, filter_ecg_records)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graficado de señales ECG filtradas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui se realiza la comparativa entre un registro preprocesado y su original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga de registros para comparativa\n",
    "record_stemi_preprocesado = wfdb.rdrecord(folder_path_preprocess_stemi + '/' + registros_stemi[0])\n",
    "\n",
    "record_stemi_original = wfdb.rdrecord(folder_path_ptb_diagnostic + '/patient001/' + registros_stemi[0])\n",
    "\n",
    "# Grafico comparativo entre los record preprocess y el original\n",
    "\n",
    "plt.figure(figsize=(15, 20))\n",
    "\n",
    "for i in range(12):\n",
    "    plt.subplot(12, 1, i+1)\n",
    "    plt.plot(record_stemi_original.p_signal[:, i], label=f'Señal original ({record_stemi_original.sig_name[i]})')\n",
    "    plt.plot(record_stemi_preprocesado.p_signal[:, i], label=f'Señal preprocesada ({record_stemi_preprocesado.sig_name[i]})')\n",
    "    plt.title(f'Comparación de la señal original y preprocesada - Canal {record_stemi_original.sig_name[i]}')\n",
    "    plt.ylabel('Amplitud (mV)')\n",
    "    plt.xlabel('Tiempo (muestras)')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.suptitle('Comparación de la señal original y preprocesada', fontsize=16)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparación de señales ECG de registros STEMI y HC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Comparar señales de stemi_records y hc_records\n",
    "hc_records_path = './Databases/PTB-XL/records500/00000'\n",
    "\n",
    "# Cargar 5 registros de pacientes STEMI preprocesados\n",
    "stemi_records_5 = []\n",
    "hc_records_5 = []\n",
    "\n",
    "# Elegir los 5 primeros registros \n",
    "for registro in registros_stemi[:5]:\n",
    "    record = wfdb.rdrecord(folder_path_preprocess_stemi + '/' + registro)\n",
    "    stemi_records_5.append(record)\n",
    "\n",
    "# Elegir los primeros 5 registros de hc_records\n",
    "\n",
    "for registro in hc_records[:5]:\n",
    "    record = wfdb.rdrecord(hc_records_path + '/' + registro)\n",
    "    hc_records_5.append(record)\n",
    "\n",
    "\n",
    "# Selección de un canal y los primeros 5 registros a comparar\n",
    "canal_a_comparar = 0  \n",
    "\n",
    "# Graficar señales de los pacientes\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "for i in range(5):\n",
    "    stemi_signal = stemi_records_5[i].p_signal[:, canal_a_comparar]\n",
    "    hc_signal = hc_records_5[i].p_signal[:, canal_a_comparar]\n",
    "\n",
    "    plt.subplot(6, 2, 2*i + 1)\n",
    "    plt.plot(stemi_signal, label=f'STEMI {i+1}', color='red')\n",
    "    plt.title(f'STEMI - Canal {canal_a_comparar + 1}, Registro {stemi_records_5[i].record_name}')\n",
    "    plt.ylabel('Amplitud (mV)')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.xlim(0,5000)\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.subplot(6, 2, 2*i + 2)\n",
    "    plt.plot(hc_signal, label=f'HC {i+1}', color='green')\n",
    "    plt.title(f'HC - Canal {canal_a_comparar + 1}, Registro {hc_records_5[i].record_name})')\n",
    "    plt.ylabel('Amplitud (mV)')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelado Simple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este apartado se comienza con la extracción de características de los registros ECG. Para esto se extraerán las características de media, desviación estándar, mínimo y máximo de los 12 canales de los registros STEMI y HC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Establecimiento de funciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui se establecen las funciones que se utilizarán para la extracción de características de los registros ECG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Función para extraer características básicas\n",
    "def extract_features(signal):\n",
    "    features = {}\n",
    "    features['mean'] = np.mean(signal)\n",
    "    features['std'] = np.std(signal)\n",
    "    features['max'] = np.max(signal)\n",
    "    features['min'] = np.min(signal)\n",
    "    return features\n",
    "# Función para extraer todas las características de todas las señales de un registro\n",
    "def extract_all_features(record):\n",
    "    for lead_signal in record.p_signal.T:  # Iterar sobre cada derivación\n",
    "        ecg_features.append(extract_features(lead_signal))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracción de características"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Registros STEMI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui se hace uso del iterador de la base de datos PTB Diagnostic ECG para extraer las características de los registros STEMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Extraer características para cada derivación del ECG\n",
    "ecg_features = []\n",
    "\n",
    "PTBDiagnosticDatabaseIterator(folder_path_preprocess_stemi,registros_stemi, extract_all_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui se muestra los resultados de las características extraidas de los registros STEMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cantidad de features extraidas\n",
    "print(\"Cantidad de features: \" + str(len(ecg_features)))\n",
    "\n",
    "# Mostrar las características extraídas como tabla\n",
    "\n",
    "# Convertir la lista de diccionarios en un DataFrame\n",
    "df_features_temp = pd.DataFrame(ecg_features)\n",
    "\n",
    "# Mostrar las primeras filas del DataFrame\n",
    "print(df_features_temp.head())\n",
    "print(df_features_temp.tail())\n",
    "\n",
    "# Uso de un indice para crear los labels de las features relacionadas con los registros STEMI\n",
    "lastIndexStemi = len(ecg_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Registros HC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui se realiza el mismo procedimiento anterior pero con los registros de los pacientes sanos (HC) extraidos de la base de datos PTB-XL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteración de extracción de caracteristicas de los registros de los pacientes sanos\n",
    "PTBXL_Iterator(extract_all_features)\n",
    "# Uso de un indice para crear los labels de las features relacionadas con los registros HC\n",
    "lastIndexHC = len(ecg_features)\n",
    "\n",
    "print(\"Cantidad de features: \" + str( lastIndexHC - lastIndexStemi))\n",
    "\n",
    "# Convirtiendo a dataframe\n",
    "import pandas as pd\n",
    "ecg_features_df = pd.DataFrame(ecg_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creación de labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se hace un una lista con los labels correspondientes a STEMI (1) y HC (0) utilizando los indices extraidos anteriormente como los margenes de la lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Creando labels, 1 para STEMI y 0 para HC\n",
    "\n",
    "labels = []\n",
    "for e in range(0,lastIndexStemi):\n",
    "    labels.append(1)\n",
    "\n",
    "for e in range(lastIndexStemi, lastIndexHC):\n",
    "    labels.append(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creación de set de entrenamiento y pruebas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este apartado se utilizan las caracteristicas extraidas de los registros STEMI y HC para crear un set de entrenamiento y pruebas con un 80% de los datos para entrenamiento y 20% para pruebas:\n",
    "\n",
    "- X_train: Este es el subconjunto de características del ECG utilizado para entrenar el modelo.\n",
    "- X_test: Este es el subconjunto de características del ECG utilizado para probar el modelo.\n",
    "- y_train: Estas son las etiquetas correspondientes al subconjunto de entrenamiento.\n",
    "- y_test: Estas son las etiquetas correspondientes al subconjunto de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Dividir en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(ecg_features_df, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creación de modelo usando Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui se hace uso del algoritmo Random Forest para la clasificación de los registros STEMI y HC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear el modelo de Random Forest\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Entrenar el modelo\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluación de modelo Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se realizan predicciones al modelo previamente creado y se contrastan con los valores reales para evaluar el rendimiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacer predicciones\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluar el rendimiento del modelo\n",
    "print(\"Precisión:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Reporte de clasificación:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se realiza la evaluación del modelo Random Forest utilizando la matriz de confusión y el indicador f1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Matriz de confusión\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.ylabel('Etiqueta real')\n",
    "plt.xlabel('Etiqueta predicha')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis Random Forest\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizando caracteristicas basicas de los canales se puede construir un modelo con una precisión de 88% utilizando Random Forest para clasificar los registros de pacientes STEMI y HC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exportación de modelo Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se hace uso de la libreria joblib para exportar el modelo entrenado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(model, 'random_forest_model_simple.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelado Complejo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelado complejo consta de la extracción de características utilizando como referencia los latidos del canal I. Para lo anterior, se utilizan punto de referencia los picos de R utilizando la libreria biosppy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Principalmente en este modelado se hará uso de 2 tipos de segmentos:\n",
    "\n",
    "- Extracción de características del complejo QRST\n",
    "- Extracción de características del segmento ST\n",
    "\n",
    "En ambos se extraeran sus respectivas características de media, desviación estándar, mínimo, máximo y duración."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Establecimiento de funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import biosppy\n",
    "import numpy as np\n",
    "\n",
    "def extract_rpeaks_indexes(record):\n",
    "    # Obtener señal i\n",
    "    signal_i = record.p_signal[:, 0]\n",
    "\n",
    "    # Obtener frecuencia de muestreo\n",
    "    fs = record.fs\n",
    "\n",
    "    ecg_data = biosppy.signals.ecg.ecg(signal=signal_i, sampling_rate=fs, show=False)\n",
    "\n",
    "    # Obtener índices de los picos R\n",
    "    rpeaks = ecg_data['rpeaks']\n",
    "\n",
    "    return rpeaks\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def find_minimum_before(index, signal, window=30):\n",
    "    \"\"\"Encuentra el mínimo en una ventana antes del índice dado.\"\"\"\n",
    "    if index <= 0:\n",
    "        raise ValueError(\"El índice debe ser mayor que 0 para buscar un mínimo antes.\")\n",
    "    \n",
    "    start = max(0, index - window)\n",
    "    segment = signal[start:index]\n",
    "    \n",
    "    if len(segment) == 0:\n",
    "        return None  # o puedes lanzar una excepción\n",
    "    return np.argmin(segment) + start\n",
    "\n",
    "\n",
    "\n",
    "def find_minimum_after(index, signal, window=30):\n",
    "    \"\"\"Encuentra el mínimo en una ventana después del índice dado.\"\"\"\n",
    "    if index >= len(signal) - 1:\n",
    "        raise ValueError(\"El índice debe ser menor que la longitud de la señal menos 1 para buscar un mínimo después.\")\n",
    "    \n",
    "    end = min(len(signal), index + window)\n",
    "    segment = signal[index:end]\n",
    "    \n",
    "    if len(segment) == 0:\n",
    "        return None  # o puedes lanzar una excepción\n",
    "    return np.argmin(segment) + index\n",
    "\n",
    "def find_maximum_after(index, signal, window=150):\n",
    "    \"\"\"Encuentra el máximo en una ventana después del índice dado.\"\"\"\n",
    "    if index >= len(signal) - 1:\n",
    "        raise ValueError(\"El índice debe ser menor que la longitud de la señal menos 1 para buscar un máximo después.\")\n",
    "    \n",
    "    end = min(len(signal), index + window)\n",
    "    segment = signal[index:end]\n",
    "    \n",
    "    if len(segment) == 0:\n",
    "        return None  # o puedes lanzar una excepción\n",
    "    return np.argmax(segment) + index\n",
    "\n",
    "\n",
    "# Extraer características de un segmento dado\n",
    "def feature_extractor(signal):\n",
    "    features = {}\n",
    "    features['mean'] = np.mean(signal)\n",
    "    features['std'] = np.std(signal)\n",
    "    features['max'] = np.max(signal)\n",
    "    features['min'] = np.min(signal)\n",
    "    features['shape'] = signal.shape[0]\n",
    "    return features\n",
    "    \n",
    "# Extrae un segmento de una señal utilizando puntos de referencia\n",
    "def extract_segment(start_point,end_point,signal):\n",
    "\n",
    "    return signal[start_point:end_point]\n",
    "# Dado un pico R, extrae las caracteristicas de los segmentos QRST y ST\n",
    "def extract_beat_features(signal,r_peak,type):\n",
    "    # Encuentra el mínimo antes del pico R para Q\n",
    "    q_point = find_minimum_before(r_peak, signal)\n",
    "    if q_point is None:\n",
    "        return\n",
    "\n",
    "    # Encuentra el mínimo después del pico R para S\n",
    "    s_point = find_minimum_after(r_peak, signal)\n",
    "    if s_point is None:\n",
    "        return\n",
    "\n",
    "    # Encuentra el máximo después del punto S para T\n",
    "    t_point = find_maximum_after(s_point, signal)\n",
    "    if t_point is None:\n",
    "        return\n",
    "\n",
    "    # Extraer segmentos QRST\n",
    "    qrst_segment = extract_segment(q_point, t_point, signal)\n",
    "    if len(qrst_segment) == 0:\n",
    "        return\n",
    "\n",
    "    st_segment = extract_segment(s_point, t_point, signal)\n",
    "    if len(st_segment) == 0:\n",
    "        return\n",
    "\n",
    "    # Extraer segmentos QRST\n",
    "    qrst_segment = extract_segment(q_point, t_point, signal)\n",
    "    st_segment = extract_segment(s_point, t_point, signal)\n",
    "\n",
    "    if type == 'STEMI':\n",
    "        # Extraer características del segmento QRST\n",
    "        qrst_features_STEMI.append(feature_extractor(qrst_segment))\n",
    "        # Extraer características del segmento ST\n",
    "        st_features_STEMI.append(feature_extractor(st_segment))\n",
    "    elif type == 'HC':\n",
    "        qrst_features_HC.append(feature_extractor(qrst_segment))\n",
    "        st_features_HC.append(feature_extractor(st_segment)) \n",
    "\n",
    "\n",
    "def extract_features_record(record,type):\n",
    "\n",
    "    r_peaks = extract_rpeaks_indexes(record)\n",
    "\n",
    "    for lead_signal in record.p_signal.T:\n",
    "\n",
    "        for r_peak in r_peaks:\n",
    "            if len(lead_signal) > 0:\n",
    "                extract_beat_features(lead_signal,r_peak,type)\n",
    "\n",
    "\n",
    "def extract_Q_points(signal, r_peaks):\n",
    "    q_points = []\n",
    "    for r_peak in r_peaks:\n",
    "        q_points.append(find_minimum_before(r_peak, signal)) \n",
    "\n",
    "    return q_points\n",
    "\n",
    "def extract_S_points(signal, r_peaks):\n",
    "    s_points = []\n",
    "    for r_peak in r_peaks:\n",
    "        s_points.append(find_minimum_after(r_peak, signal)) \n",
    "\n",
    "    return s_points\n",
    "\n",
    "def extract_T_points(signal,s_points):\n",
    "    t_points = []\n",
    "    for s_point in s_points:\n",
    "        t_points.append(find_maximum_after(s_point, signal))\n",
    "    return t_points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo de la identificación de los picos R y puntos QST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracción de puntos y picos R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import biosppy\n",
    "\n",
    "fs = 500\n",
    "\n",
    "# Cargar un registro STEMI\n",
    "record_stemi = wfdb.rdrecord(folder_path_preprocess_stemi + '/' + registros_stemi[0])\n",
    "\n",
    "i_derivation = record_stemi.p_signal[:, 0]\n",
    "\n",
    "r_peaks = extract_rpeaks_indexes(record_stemi)\n",
    "\n",
    "q_points = extract_Q_points(i_derivation, r_peaks)\n",
    "\n",
    "s_points = extract_S_points(i_derivation, r_peaks)\n",
    "\n",
    "t_points = extract_T_points(i_derivation,s_points)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graficado de un complejo QRST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graficar lo puntos\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.plot(i_derivation, label='Derivación I')\n",
    "plt.plot(r_peaks, i_derivation[r_peaks], 'ro', label='Picos R')\n",
    "plt.plot(q_points, i_derivation[q_points], 'yo', label='Q' )\n",
    "plt.plot(s_points, i_derivation[s_points], 'bo', label='S')\n",
    "plt.plot(t_points, i_derivation[t_points], 'go', label='T')\n",
    "plt.title('Complejo QRST de un registro STEMI')\n",
    "plt.xlim(q_points[0] -20,t_points[0]+20)\n",
    "plt.xlabel('Tiempo (muestras)')\n",
    "plt.ylabel('Amplitud (mV)')\n",
    "plt.legend(loc='lower left')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graficado de varios complejos QRST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# graficar lo puntos\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.plot(i_derivation, label='Derivación I')\n",
    "plt.plot(r_peaks, i_derivation[r_peaks], 'ro', label='Picos R')\n",
    "plt.plot(q_points, i_derivation[q_points], 'yo', label='Q' )\n",
    "plt.plot(s_points, i_derivation[s_points], 'bo', label='S')\n",
    "plt.plot(t_points, i_derivation[t_points], 'go', label='T')\n",
    "plt.title('Complejos QRST de un registro STEMI')\n",
    "plt.xlim(0,5000)\n",
    "plt.xlabel('Tiempo (muestras)')\n",
    "plt.ylabel('Amplitud (mV)')\n",
    "plt.legend(loc='lower left')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracción de features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui se realiza la extracción de "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "st_features_HC = []\n",
    "qrst_features_HC = []\n",
    "\n",
    "\n",
    "PTBXL_Iterator(lambda record: extract_features_record(record, 'HC'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Cantidad de features QRST HC: \" + str(len(qrst_features_HC)))\n",
    "print(\"Cantidad de features ST HC: \" + str(len(st_features_HC)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "st_features_STEMI = []\n",
    "qrst_features_STEMI = []\n",
    "\n",
    "PTBDiagnosticDatabaseIterator(folder_path_preprocess_stemi,registros_stemi,lambda record: extract_features_record(record, 'STEMI'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Cantidad de features QRST STEMI: \" + str(len(qrst_features_STEMI)))\n",
    "\n",
    "print(\"Cantidad de features ST STEMI: \" + str(len(st_features_STEMI)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balanceando features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debido a que la extracción de features es muy deproporcionada respecto a los registros STEMI y HC, se procede a balancear las features para que el modelo pueda aprender de manera correcta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limitando las features de registros STEMI a la cantidad de features de los registros HC\n",
    "qrst_features_STEMI_truncated = qrst_features_STEMI[:len(qrst_features_HC)]\n",
    "st_features_STEMI_truncated = st_features_STEMI[:len(st_features_HC)]\n",
    "\n",
    "print(\"Cantidad de features QRST STEMI truncados: \" + str(len(qrst_features_STEMI_truncated)))\n",
    "\n",
    "print(\"Cantidad de features ST truncados: \" + str(len(st_features_STEMI_truncated)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenación de complejos QRST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenación de features\n",
    "QRST_complex_HC_STEMI = qrst_features_STEMI_truncated+qrst_features_HC\n",
    "\n",
    "# Creación de dataframe\n",
    "DF_QRST_HC_STEMI = pd.DataFrame(QRST_complex_HC_STEMI)\n",
    "\n",
    "DF_QRST_HC_STEMI.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenación de segmentos ST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenación\n",
    "ST_Segments_HC_STEMI = st_features_STEMI_truncated+st_features_HC\n",
    "\n",
    "# Creación de dataframe\n",
    "DF_ST_Segments_HC_STEMI = pd.DataFrame(ST_Segments_HC_STEMI)\n",
    "\n",
    "DF_ST_Segments_HC_STEMI.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creación de labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creando labels, 1 para STEMI y 0 para HC\n",
    "\n",
    "length_features_HC = len(qrst_features_HC)\n",
    "length_features_STEMI = len(qrst_features_STEMI_truncated)\n",
    "\n",
    "labels = []\n",
    "for e in range(0,length_features_STEMI):\n",
    "    labels.append(1)\n",
    "\n",
    "for e in range(length_features_STEMI, DF_QRST_HC_STEMI.shape[0]):\n",
    "    labels.append(0)\n",
    "\n",
    "print(\"Cantidad de labels: \", len(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creación de set de entrenamiento y pruebas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir en entrenamiento y prueba para los complejos QRST\n",
    "X_QRST_train, X_QRST_test, y_QRST_train, y_QRST_test = train_test_split(DF_QRST_HC_STEMI, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Dividir en entrenamiento y prueba para los segmentos ST\n",
    "X_ST_train, X_ST_test, y_ST_train, y_ST_test = train_test_split(DF_ST_Segments_HC_STEMI, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creación de modelos usando Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear el modelo de Random Forest para los complejos QRST\n",
    "model_qrst = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Entrenar el modelo QRST\n",
    "model_qrst.fit(X_QRST_train, y_QRST_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear el modelo de Random Forest para los segmentos ST\n",
    "model_st = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Entrenar el modelo ST\n",
    "model_st.fit(X_ST_train, y_ST_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluación de modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacer predicciones en modelo QRST\n",
    "y_QRST_pred = model_qrst.predict(X_QRST_test)\n",
    "\n",
    "# Evaluar el rendimiento del modelo QRST\n",
    "print(\"Precisión:\", accuracy_score(y_QRST_test, y_QRST_pred))\n",
    "print(\"Reporte de clasificación:\\n\", classification_report(y_QRST_test, y_QRST_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacer predicciones en modelo ST\n",
    "y_ST_pred = model_st.predict(X_ST_test)\n",
    "\n",
    "# Evaluar el rendimiento del modelo ST\n",
    "print(\"Precisión:\", accuracy_score(y_ST_test, y_ST_pred))\n",
    "print(\"Reporte de clasificación:\\n\", classification_report(y_ST_test, y_ST_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Matriz de confusión\n",
    "cm_QRST = confusion_matrix(y_QRST_test, y_QRST_pred)\n",
    "sns.heatmap(cm_QRST, annot=True, fmt='d', cmap='Blues')\n",
    "plt.ylabel('Etiqueta real')\n",
    "plt.xlabel('Etiqueta predicha')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de confusión\n",
    "cm_ST = confusion_matrix(y_ST_test, y_ST_pred)\n",
    "sns.heatmap(cm_ST, annot=True, fmt='d', cmap='Blues')\n",
    "plt.ylabel('Etiqueta real')\n",
    "plt.xlabel('Etiqueta predicha')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis de resultados de ambos modelos complejos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, recall_score\n",
    "\n",
    "# Gráfico comparativo entre accuracy\n",
    "# Calcular metricas\n",
    "accuracy_qrst = accuracy_score(y_QRST_test, y_QRST_pred)\n",
    "accuracy_st = accuracy_score(y_ST_test, y_ST_pred)\n",
    "f1_qrst = f1_score(y_QRST_test, y_QRST_pred)\n",
    "f1_st = f1_score(y_ST_test, y_ST_pred)\n",
    "recall_qrst = recall_score(y_QRST_test, y_QRST_pred)\n",
    "recall_st = recall_score(y_ST_test, y_ST_pred)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "metrics = ['Accuracy', 'F1 Score', 'Recall']\n",
    "qrst_values = [accuracy_qrst, f1_qrst, recall_qrst]\n",
    "st_values = [accuracy_st, f1_st, recall_st]\n",
    "\n",
    "x = range(len(metrics))\n",
    "bar_width = 0.4\n",
    "plt.bar(x, qrst_values, width=bar_width, label='Random Forest QRST', align='center', color='orange')\n",
    "plt.bar([i + bar_width for i in x], st_values, width=bar_width, label='Random Forest ST', align='center', color='purple')\n",
    "\n",
    "# Agregar porcentajes\n",
    "for i in range(len(metrics)):\n",
    "    plt.text(i, qrst_values[i] + 0.005, f'{qrst_values[i]*100:.2f}%', ha='center', color='orange')\n",
    "    plt.text(i + bar_width, st_values[i] + 0.005, f'{st_values[i]*100:.2f}%', ha='center', color='purple')\n",
    "\n",
    "plt.xlabel('Metrics')\n",
    "plt.ylabel('Scores')\n",
    "plt.title('Comparativa de Accuracy, F1 Score, y Recall')\n",
    "plt.xticks([i + bar_width / 2 for i in x], metrics)\n",
    "plt.ylim([0.9, 1])\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede observar en los resultados, los indicadores del complejo QRST son mayores a los del segmento ST. Esto debido a que se proporciona una visión mas general del latido. Pero en general la diferencia entre estos indicadores es de alrededor de un 5% del total.\n",
    "\n",
    "Cabe destacar que aún con esta diferencia entre los resultados, tanto los indicadores del complejo QRST y del segmento ST son valores mayores al 90% lo cual indica que el modelo es capaz de clasificar de manera precisa la gran mayoria los registros STEMI y HC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exportación de modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui se exportan ambos modelos generados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "# Exportación de modelo qrst\n",
    "joblib.dump(model_qrst, 'random_forest_model_complex_qrst.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportación de modelo qrst\n",
    "joblib.dump(model_qrst, 'random_forest_model_complex_st.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sección donde se resumen los resultados obtenidos en el proyecto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gráficos comparativos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grafico comparativo entre modelo simple y los modelos complejos\n",
    "\n",
    "# Calcular metricas\n",
    "accuracy_simple = accuracy_score(y_test, y_pred)\n",
    "accuracy_qrst = accuracy_score(y_QRST_test, y_QRST_pred)\n",
    "accuracy_st = accuracy_score(y_ST_test, y_ST_pred)\n",
    "\n",
    "\n",
    "f1_simple = f1_score(y_test, y_pred)\n",
    "f1_qrst = f1_score(y_QRST_test, y_QRST_pred)\n",
    "f1_st = f1_score(y_ST_test, y_ST_pred)\n",
    "\n",
    "recall_simple = recall_score(y_test, y_pred)\n",
    "recall_qrst = recall_score(y_QRST_test, y_QRST_pred)\n",
    "recall_st = recall_score(y_ST_test, y_ST_pred)\n",
    "\n",
    "# Crear plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "metrics = ['Accuracy', 'F1 Score', 'Recall']\n",
    "simple_values = [accuracy_simple, f1_simple, recall_simple]\n",
    "qrst_values = [accuracy_qrst, f1_qrst, recall_qrst]\n",
    "st_values = [accuracy_st, f1_st, recall_st]\n",
    "\n",
    "x = range(len(metrics))\n",
    "bar_width = 0.2\n",
    "plt.bar(x, simple_values, width=bar_width, label='Random Forest Simple', align='center', color='orange')\n",
    "plt.bar([i + bar_width for i in x], qrst_values, width=bar_width, label='Random Forest QRST', align='center', color='purple')\n",
    "plt.bar([i + bar_width*2 for i in x], st_values, width=bar_width, label='Random Forest ST', align='center', color='blue')\n",
    "\n",
    "# Agregar porcentajes en las barras\n",
    "for i in range(len(metrics)):\n",
    "    plt.text(i, simple_values[i] + 0.002, f'{simple_values[i]*100:.2f}%', ha='center', color='orange')\n",
    "    plt.text(i + bar_width, qrst_values[i] + 0.002, f'{qrst_values[i]*100:.2f}%', ha='center', color='purple')\n",
    "    plt.text(i + bar_width*2, st_values[i] + 0.002, f'{st_values[i]*100:.2f}%', ha='center', color='blue')\n",
    "\n",
    "plt.xlabel('Metrics')\n",
    "plt.ylabel('Scores')\n",
    "plt.title('Comparativa de Accuracy, F1 Score, y Recall')\n",
    "plt.xticks([i + bar_width  for i in x], metrics)\n",
    "plt.ylim([0.85, 1])\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sobre los resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo entrenado con las características completas del complejo QRST muestra una mayor capacidad para predecir la etiqueta de registro, ya sea como sano o de tipo STEMI. Es importante señalar que las diferencias entre el modelo simple, que utiliza características generales de cada canal del registro, y el modelo complejo, basado en la extracción del segmento ST, son mínimas, con una variación aproximada del 1%. Esto sugiere que, si es necesario optimizar recursos, optar por una identificación general de los registros sería preferible. Sin embargo, si se requiere una mayor precisión en el modelo, la opción más adecuada sería el modelado complejo que utiliza los puntos QRST."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
